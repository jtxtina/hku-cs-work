{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n",
    "The Goal is to minimize the cost function for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "    \\min_{w, b} \\frac{1}{2} \\textbf{w}^T \\textbf{w}\n",
    "$$\n",
    "$$\n",
    "    s.t: \\,\\, \\forall i\\in[N]: y_n (\\textbf{w}^Tx_n+b) \\geqslant 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Part 1 will use Breast Cancer to illustrate and Part 2 will use iris dataset to illustrate*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use the following libraries:\n",
    "* pandas --- only to load in data\n",
    "* numpy\n",
    "* cvxopt\n",
    "* sklearn --- only to compare the outcome of my SVM with the library SVM in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cvxopt import matrix, solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Using cvxopt.solvers.qp(P, q, G, h, A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard form of Quadratic Programming(QP) at cvxopt document is:\n",
    "$$\n",
    "    \\text{min }\\frac{1}{2}x^TPx+q^Tx\\\\\n",
    "    Gx \\preceq h\\\\\n",
    "    Ax=b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing\n",
    "* I use Pandas to load in the data from the breast cancer dataset. \n",
    "* Also, for the y(label), I have changed every 0 to -1 in order to simplify later work without loss of generosity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_x_train = pd.read_csv('dataset_files/cancer_X_train.csv')\n",
    "cancer_y_train = pd.read_csv('dataset_files/cancer_Y_train.csv')\n",
    "cancer_x_train = cancer_x_train.iloc[0:, ].values\n",
    "cancer_y_train = cancer_y_train.iloc[0:, 0].values\n",
    "\n",
    "cancer_x_test = pd.read_csv('dataset_files/cancer_X_test.csv')\n",
    "cancer_y_test = pd.read_csv('dataset_files/cancer_Y_test.csv')\n",
    "cancer_x_test = cancer_x_test.iloc[0:, ].values\n",
    "cancer_y_test = cancer_y_test.iloc[0:, 0].values\n",
    "\n",
    "cancer_y_train=cancer_y_train.astype(float)\n",
    "cancer_y_train= (cancer_y_train-0.5)*2\n",
    "\n",
    "cancer_y_test=cancer_y_test.astype(float)\n",
    "cancer_y_test= (cancer_y_test-0.5)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Soft-margin SVM with QP by cvxopt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "under this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_soft():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.w = self.b = None\n",
    "\n",
    "    def fit(self, X, y, C=1.0):\n",
    "        n = len(X)\n",
    "        d = len(X[0])\n",
    "        #initialize p q G h\n",
    "        self.P = matrix(np.identity(d + 1 + n, dtype=np.float))  \n",
    "        self.q = matrix(np.zeros((d + 1 + n), dtype=np.float))\n",
    "        self.G = matrix(np.zeros((n + n, d + 1 + n), dtype=np.float))\n",
    "        self.h = -matrix(np.ones((n+n,), dtype=np.float))     \n",
    "        \n",
    "        #put in values for p q G h\n",
    "        self.q[-n:,0] = C\n",
    "\n",
    "        self.h[-n:,0] = 0\n",
    "        \n",
    "        self.P[0, 0] = 0\n",
    "        self.P[1+d:, :] = 0\n",
    "        \n",
    "        for i in range(n):\n",
    "            self.G[i, 0] = -y[i]\n",
    "            self.G[i, 1: 1+d] = -X[i, :] * y[i]\n",
    "            self.G[i, 1 + d + i] = -1\n",
    "            self.G[i + n, i + d + 1] = -1 \n",
    "            \n",
    "        # QP\n",
    "        sol = solvers.qp(self.P,self.q,self.G,self.h)\n",
    "\n",
    "        self.w = np.zeros(d,)\n",
    "        self.b = sol[\"x\"][0] \n",
    "        for i in range(1, d + 1):\n",
    "            self.w[i - 1] = sol[\"x\"][i]\n",
    "        \n",
    "        return self.w, self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(self.w, X.T) + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results under different C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. C = 0 (i.e no slack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0333e+00  5.1985e+01  3e+03  3e+00  2e+05\n",
      " 1:  3.7636e-01 -1.1988e+02  1e+02  1e-01  7e+03\n",
      " 2:  6.4760e-03 -7.3443e+00  7e+00  7e-03  4e+02\n",
      " 3:  1.1177e-03 -2.2768e-01  2e-01  2e-04  1e+01\n",
      " 4:  5.9596e-05 -2.3184e-02  2e-02  2e-05  1e+00\n",
      " 5:  1.0621e-06 -1.1134e-03  1e-03  1e-06  6e-02\n",
      " 6:  5.2714e-07 -4.3139e-05  4e-05  4e-08  2e-03\n",
      " 7:  7.1622e-08 -6.2193e-06  6e-06  6e-09  3e-04\n",
      " 8:  2.6419e-10 -4.8977e-07  5e-07  4e-10  2e-05\n",
      " 9:  2.6866e-14 -4.9455e-09  5e-09  4e-12  3e-07\n",
      "10:  2.6866e-18 -4.9455e-11  5e-11  4e-14  3e-09\n",
      "Optimal solution found.\n",
      "Training set accuracy： 62.6761 %\n",
      "Testing set accuracy： 62.9371 %\n"
     ]
    }
   ],
   "source": [
    "svm_soft = SVM_soft()\n",
    "svm_soft.fit(cancer_x_train, cancer_y_train, 0)\n",
    "\n",
    "print(\"Training set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_train) == cancer_y_train).mean() * 100))\n",
    "print(\"Testing set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_test) == cancer_y_test).mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. C = 1.0 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.1583e+02  8.9218e+02  5e+03  4e+00  8e+03\n",
      " 1:  3.5679e+02 -2.8004e+02  9e+02  6e-01  1e+03\n",
      " 2:  2.2042e+02 -1.2900e+02  5e+02  3e-01  5e+02\n",
      " 3:  1.4552e+02 -4.9921e+01  2e+02  1e-01  2e+02\n",
      " 4:  9.5396e+01 -9.8586e+00  1e+02  6e-02  1e+02\n",
      " 5:  6.4752e+01  1.5392e+01  6e+01  2e-02  4e+01\n",
      " 6:  4.7356e+01  2.8937e+01  2e+01  8e-03  1e+01\n",
      " 7:  4.1609e+01  3.4227e+01  8e+00  9e-04  2e+00\n",
      " 8:  3.9830e+01  3.5307e+01  5e+00  5e-04  9e-01\n",
      " 9:  3.8542e+01  3.6125e+01  2e+00  6e-05  1e-01\n",
      "10:  3.7852e+01  3.6489e+01  1e+00  2e-05  4e-02\n",
      "11:  3.7139e+01  3.6969e+01  2e-01  2e-06  4e-03\n",
      "12:  3.7046e+01  3.7041e+01  5e-03  4e-08  8e-05\n",
      "13:  3.7043e+01  3.7043e+01  9e-05  7e-10  1e-06\n",
      "14:  3.7043e+01  3.7043e+01  2e-06  9e-12  1e-07\n",
      "15:  3.7043e+01  3.7043e+01  8e-08  9e-14  6e-06\n",
      "16:  3.7043e+01  3.7043e+01  2e-09  7e-15  4e-05\n",
      "Terminated (singular KKT matrix).\n",
      "Training set accuracy： 96.4789 %\n",
      "Testing set accuracy： 95.1049 %\n"
     ]
    }
   ],
   "source": [
    "svm_soft.fit(cancer_x_train, cancer_y_train, 1)\n",
    "\n",
    "print(\"Training set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_train) == cancer_y_train).mean() * 100))\n",
    "print(\"Testing set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_test) == cancer_y_test).mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. C = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.6643e+04  2.4753e+04  8e+04  2e+01  2e+03\n",
      " 1: -1.7248e+03 -4.9573e+03  2e+04  4e+00  5e+02\n",
      " 2:  4.7553e+02 -3.3901e+03  1e+04  2e+00  2e+02\n",
      " 3:  1.0082e+03 -1.4933e+03  5e+03  9e-01  9e+01\n",
      " 4:  8.6716e+02 -4.2482e+02  2e+03  3e-01  4e+01\n",
      " 5:  5.0712e+02  9.9270e+01  6e+02  7e-02  8e+00\n",
      " 6:  4.5756e+02  1.8448e+02  4e+02  3e-02  4e+00\n",
      " 7:  4.2379e+02  2.1449e+02  3e+02  2e-02  2e+00\n",
      " 8:  3.8802e+02  2.4142e+02  2e+02  1e-02  1e+00\n",
      " 9:  3.6076e+02  2.6155e+02  1e+02  6e-03  6e-01\n",
      "10:  3.3283e+02  2.8005e+02  6e+01  2e-03  2e-01\n",
      "11:  3.2647e+02  2.7991e+02  5e+01  7e-04  7e-02\n",
      "12:  3.1374e+02  2.8905e+02  3e+01  2e-04  2e-02\n",
      "13:  3.0212e+02  2.9725e+02  5e+00  4e-05  4e-03\n",
      "14:  2.9962e+02  2.9889e+02  7e-01  8e-15  2e-10\n",
      "15:  2.9925e+02  2.9924e+02  1e-02  7e-15  2e-09\n",
      "16:  2.9924e+02  2.9924e+02  2e-04  7e-15  7e-09\n",
      "Optimal solution found.\n",
      "Training set accuracy： 97.6526 %\n",
      "Testing set accuracy： 95.8042 %\n"
     ]
    }
   ],
   "source": [
    "svm_soft.fit(cancer_x_train, cancer_y_train, 10)\n",
    "\n",
    "print(\"Training set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_train) == cancer_y_train).mean() * 100))\n",
    "print(\"Testing set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_test) == cancer_y_test).mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. C = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7140e+06  1.8770e+06  6e+06  2e+02  2e+03\n",
      " 1: -4.6506e+05 -3.8584e+05  1e+06  4e+01  4e+02\n",
      " 2: -1.0816e+05 -2.5811e+05  8e+05  2e+01  2e+02\n",
      " 3:  8.5495e+03 -1.0262e+05  3e+05  7e+00  6e+01\n",
      " 4:  3.5538e+04 -1.7831e+04  1e+05  1e+00  1e+01\n",
      " 5:  2.3768e+04 -5.7732e+01  2e+04  2e-13  1e-10\n",
      " 6:  6.0089e+03  6.5320e+02  5e+03  6e-14  1e-10\n",
      " 7:  5.8448e+03  8.4877e+02  5e+03  5e-14  2e-10\n",
      " 8:  5.1260e+03  1.1174e+03  4e+03  4e-14  1e-10\n",
      " 9:  4.6600e+03  1.1461e+03  4e+03  3e-14  2e-10\n",
      "10:  3.2560e+03  1.3936e+03  2e+03  1e-14  2e-10\n",
      "11:  3.2653e+03  1.6005e+03  2e+03  1e-14  8e-11\n",
      "12:  2.7493e+03  1.6673e+03  1e+03  8e-15  2e-10\n",
      "13:  2.6646e+03  1.6981e+03  1e+03  7e-15  1e-10\n",
      "14:  2.3249e+03  1.8632e+03  5e+02  6e-15  7e-11\n",
      "15:  2.2333e+03  1.9034e+03  3e+02  6e-15  1e-10\n",
      "16:  2.0754e+03  1.9853e+03  9e+01  7e-15  1e-10\n",
      "17:  2.0404e+03  2.0066e+03  3e+01  6e-15  6e-10\n",
      "18:  2.0238e+03  2.0173e+03  6e+00  6e-15  6e-10\n",
      "19:  2.0204e+03  2.0203e+03  1e-01  6e-15  7e-10\n",
      "20:  2.0204e+03  2.0204e+03  1e-03  6e-15  4e-09\n",
      "Optimal solution found.\n",
      "Training set accuracy： 98.8263 %\n",
      "Testing set accuracy： 96.5035 %\n"
     ]
    }
   ],
   "source": [
    "svm_soft.fit(cancer_x_train, cancer_y_train, 100)\n",
    "\n",
    "print(\"Training set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_train) == cancer_y_train).mean() * 100))\n",
    "print(\"Testing set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_test) == cancer_y_test).mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. C = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.5469e+00  6.0390e+01  3e+03  3e+00  2e+05\n",
      " 1:  8.4936e+00 -1.0587e+02  1e+02  1e-01  6e+03\n",
      " 2:  7.3162e+00 -1.3283e+01  2e+01  1e-02  8e+02\n",
      " 3:  4.4006e+00 -2.7591e+00  7e+00  4e-03  2e+02\n",
      " 4:  2.0767e+00 -5.9346e-01  3e+00  1e-03  8e+01\n",
      " 5:  1.2542e+00 -5.3720e-02  1e+00  6e-04  4e+01\n",
      " 6:  8.5149e-01  1.9384e-01  7e-01  3e-04  2e+01\n",
      " 7:  7.3421e-01  2.7530e-01  5e-01  2e-04  1e+01\n",
      " 8:  5.3148e-01  4.1719e-01  1e-01  3e-05  2e+00\n",
      " 9:  4.7478e-01  4.5625e-01  2e-02  3e-06  2e-01\n",
      "10:  4.6681e-01  4.6166e-01  5e-03  3e-07  2e-02\n",
      "11:  4.6466e-01  4.6340e-01  1e-03  8e-15  3e-11\n",
      "12:  4.6402e-01  4.6399e-01  3e-05  8e-15  2e-11\n",
      "13:  4.6400e-01  4.6400e-01  1e-06  8e-15  7e-10\n",
      "14:  4.6400e-01  4.6400e-01  1e-08  8e-15  8e-10\n",
      "Optimal solution found.\n",
      "Training set accuracy： 95.7746 %\n",
      "Testing set accuracy：  93.007 %\n"
     ]
    }
   ],
   "source": [
    "svm_soft.fit(cancer_x_train, cancer_y_train, 1e-2)\n",
    "\n",
    "print(\"Training set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_train) == cancer_y_train).mean() * 100))\n",
    "print(\"Testing set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_test) == cancer_y_test).mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. C = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.0388e+00  5.2069e+01  3e+03  3e+00  2e+05\n",
      " 1:  4.5787e-01 -1.1974e+02  1e+02  1e-01  7e+03\n",
      " 2:  9.3226e-02 -7.4320e+00  8e+00  7e-03  4e+02\n",
      " 3:  8.6052e-02 -3.1371e-01  4e-01  3e-04  2e+01\n",
      " 4:  6.9402e-02 -9.9119e-02  2e-01  1e-04  6e+00\n",
      " 5:  4.2124e-02 -2.5996e-02  7e-02  4e-05  2e+00\n",
      " 6:  2.2383e-02 -5.3093e-03  3e-02  2e-05  9e-01\n",
      " 7:  1.4590e-02  1.2355e-03  1e-02  7e-06  4e-01\n",
      " 8:  1.0050e-02  4.6608e-03  5e-03  2e-06  1e-01\n",
      " 9:  7.9701e-03  6.1053e-03  2e-03  7e-07  4e-02\n",
      "10:  7.4128e-03  6.5384e-03  9e-04  2e-07  1e-02\n",
      "11:  7.0887e-03  6.7618e-03  3e-04  4e-08  2e-03\n",
      "12:  6.9422e-03  6.8706e-03  7e-05  3e-09  2e-04\n",
      "13:  6.9187e-03  6.8863e-03  3e-05  6e-10  4e-05\n",
      "14:  6.9033e-03  6.9000e-03  3e-06  2e-11  1e-06\n",
      "15:  6.9016e-03  6.9016e-03  5e-08  3e-13  2e-08\n",
      "Optimal solution found.\n",
      "Training set accuracy： 93.4272 %\n",
      "Testing set accuracy： 94.4056 %\n"
     ]
    }
   ],
   "source": [
    "svm_soft.fit(cancer_x_train, cancer_y_train, 1e-4)\n",
    "\n",
    "print(\"Training set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_train) == cancer_y_train).mean() * 100))\n",
    "print(\"Testing set accuracy：{:8.6} %\".format((svm_soft.predict(cancer_x_test) == cancer_y_test).mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results under sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 1e-10:  62.9371 %\n",
      "C = 1:  95.8042 %\n",
      "C = 10:  96.5035 %\n",
      "C = 100:  95.8042 %\n",
      "C = 1e-2:   93.007 %\n",
      "C = 1e-4:  94.4056 %\n"
     ]
    }
   ],
   "source": [
    "svm_1 = SVC(kernel = 'linear', C=1e-10, random_state=1)\n",
    "svm_2 = SVC(kernel = 'linear', C=1, random_state=1)\n",
    "svm_3 = SVC(kernel = 'linear', C=10, random_state=1)\n",
    "svm_4 = SVC(kernel = 'linear', C=100, random_state=1)\n",
    "svm_5 = SVC(kernel = 'linear', C=1e-2, random_state=1)\n",
    "svm_6 = SVC(kernel = 'linear', C=1e-4, random_state=1)\n",
    "svm_1.fit(cancer_x_train, cancer_y_train)\n",
    "svm_2.fit(cancer_x_train, cancer_y_train)\n",
    "svm_3.fit(cancer_x_train, cancer_y_train)\n",
    "svm_4.fit(cancer_x_train, cancer_y_train)\n",
    "svm_5.fit(cancer_x_train, cancer_y_train)\n",
    "svm_6.fit(cancer_x_train, cancer_y_train)\n",
    "\n",
    "print(\"C = 1e-10: {:8.6} %\".format((svm_1.predict(cancer_x_test) == cancer_y_test).mean() * 100))\n",
    "print(\"C = 1: {:8.6} %\".format((svm_2.predict(cancer_x_test) == cancer_y_test).mean() * 100))\n",
    "print(\"C = 10: {:8.6} %\".format((svm_3.predict(cancer_x_test) == cancer_y_test).mean() * 100))\n",
    "print(\"C = 100: {:8.6} %\".format((svm_4.predict(cancer_x_test) == cancer_y_test).mean() * 100))\n",
    "print(\"C = 1e-2: {:8.6} %\".format((svm_5.predict(cancer_x_test) == cancer_y_test).mean() * 100))\n",
    "print(\"C = 1e-4: {:8.6} %\".format((svm_6.predict(cancer_x_test) == cancer_y_test).mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above statistics, it is very obvious that my SVM has a similar performance with the SVM in the sklearn library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. When C is small, the training set accuracy is small or near zero(when C = 0 i.e no slack). And when C gets bigger, the training set accuracy will also be bigger.\n",
    "2. When C gets bigger, the time used to find the optimal solution is longer(shown by the number of lines each fit).\n",
    "3. When C gets bigger, the testing set accuracy has a tendency to be bigger. However, bigger C can also give a lower testing set accuracy than a smaller C considering individual cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Dealing with several classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have to deal with multiple case, we will reduce the problem into dealing with 2 classes and use the above SVM:\n",
    "1. One verses one SVM(OVO):  we will create a SVM between each 2 classes. Thus it will be k(k-1)/2 in total(k is the number of classes). Then we will use a voting strategy called 'Max win' to decide its final result. During this process, each sample will be classified into one class each SVM and we will add one credit to this class. In the end, each sample will have different credits on each class labels and we will label it with the max credit class. If the credit is equal. Then we choose the one that come last for simplicity.\n",
    "\n",
    "2. One verses rest SVM(OVR): we label one class to be the positive label, and the others to be the negative label. Thus we still have 2 labels in total for one SVM. And we will need to create k SVMs in total(k is the number of classes) and will get k results. If several SVM label one same class to be positive, then we just choose the one that come last for simplicity.If a sample has no positive cases in each SVM, then we label it to be the last one for simplicity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "* I use Pandas to load in the data from the iris dataset. \n",
    "* For the y(label), when training the model, I will use 1 to represent the positive class and -1 to represent the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_x_train = pd.read_csv('dataset_files/iris_X_train.csv')\n",
    "iris_y_train = pd.read_csv('dataset_files/iris_Y_train.csv')\n",
    "iris_x_train = iris_x_train.iloc[0:, ].values\n",
    "iris_y_train = iris_y_train.iloc[0:, 0].values\n",
    "\n",
    "iris_x_test = pd.read_csv('dataset_files/iris_X_test.csv')\n",
    "iris_y_test = pd.read_csv('dataset_files/iris_Y_test.csv')\n",
    "iris_x_test = iris_x_test.iloc[0:, ].values\n",
    "iris_y_test = iris_y_test.iloc[0:, 0].values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVO(One vs one)\n",
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_y_train_0 = np.where(iris_y_train == 0, 1, -1).astype(float)\n",
    "iris_y_train_1 = np.where(iris_y_train == 1, 1, -1).astype(float)\n",
    "iris_y_train_2 = np.where(iris_y_train == 2, 1, -1).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8841e+01  2.2664e+02  8e+02  4e+00  4e+01\n",
      " 1:  1.3817e+02  2.0346e+01  1e+02  2e-01  2e+00\n",
      " 2:  6.6936e+01  5.0224e+01  2e+01  3e-02  3e-01\n",
      " 3:  6.0970e+01  5.8252e+01  3e+00  4e-03  4e-02\n",
      " 4:  6.0100e+01  5.9598e+01  5e-01  6e-04  6e-03\n",
      " 5:  5.9908e+01  5.9828e+01  9e-02  9e-05  8e-04\n",
      " 6:  5.9874e+01  5.9871e+01  3e-03  3e-06  3e-05\n",
      " 7:  5.9873e+01  5.9873e+01  8e-05  5e-08  4e-07\n",
      " 8:  5.9873e+01  5.9873e+01  2e-06  5e-10  5e-09\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.1989e+01  1.9277e+02  8e+02  4e+00  3e+01\n",
      " 1:  8.4593e+01 -2.1960e+01  1e+02  4e-01  3e+00\n",
      " 2:  4.4669e+01 -1.1474e+01  7e+01  2e-01  1e+00\n",
      " 3:  2.0368e+01  6.2209e+00  2e+01  3e-02  3e-01\n",
      " 4:  1.4985e+01  1.0931e+01  5e+00  9e-03  6e-02\n",
      " 5:  1.3704e+01  1.2384e+01  1e+00  2e-03  1e-02\n",
      " 6:  1.3129e+01  1.2901e+01  2e-01  3e-04  2e-03\n",
      " 7:  1.3037e+01  1.2973e+01  6e-02  1e-15  5e-13\n",
      " 8:  1.3006e+01  1.3003e+01  2e-03  2e-15  1e-12\n",
      " 9:  1.3005e+01  1.3005e+01  3e-05  1e-15  8e-12\n",
      "10:  1.3005e+01  1.3005e+01  3e-07  1e-15  5e-12\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.0213e+01  1.6846e+02  8e+02  4e+00  7e+01\n",
      " 1:  5.3678e+01 -4.6989e+01  1e+02  4e-01  8e+00\n",
      " 2:  1.4447e+01 -9.3479e+00  3e+01  8e-02  2e+00\n",
      " 3:  2.0020e+00 -2.1132e-01  2e+00  4e-03  7e-02\n",
      " 4:  9.4342e-01  4.1180e-01  6e-01  9e-04  2e-02\n",
      " 5:  9.9326e-01  5.2565e-01  5e-01  5e-04  1e-02\n",
      " 6:  8.0279e-01  6.9595e-01  1e-01  1e-04  2e-03\n",
      " 7:  7.5247e-01  7.4418e-01  8e-03  2e-07  3e-06\n",
      " 8:  7.4811e-01  7.4801e-01  9e-05  2e-09  3e-08\n",
      " 9:  7.4806e-01  7.4806e-01  9e-07  2e-11  3e-10\n",
      "10:  7.4806e-01  7.4806e-01  9e-09  2e-13  3e-12\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.04603435,  0.52172246, -1.00316485, -0.46417955]),\n",
       " 1.4505610996768012)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_soft_0 = SVM_soft()\n",
    "svm_soft_1 = SVM_soft()\n",
    "svm_soft_2 = SVM_soft()\n",
    "\n",
    "svm_soft_0.fit(iris_x_train, iris_y_train_0, 1)\n",
    "svm_soft_1.fit(iris_x_train, iris_y_train_1, 1)\n",
    "svm_soft_2.fit(iris_x_train, iris_y_train_2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1 = svm_soft_0.predict(iris_x_test)\n",
    "predict2 = svm_soft_1.predict(iris_x_test)\n",
    "predict3 = svm_soft_2.predict(iris_x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list0 = []\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for i in range(len(predict1)):\n",
    "    if predict1[i] == 1:\n",
    "        list0.append(i)\n",
    "    if predict2[i] == 1:\n",
    "        list1.append(i)\n",
    "    if predict3[i] == 1:\n",
    "        list2.append(i)\n",
    "\n",
    "\n",
    "result = [2] * len(predict1)\n",
    "\n",
    "for k in list0:\n",
    "    result[k] = 0\n",
    "for k in list1:\n",
    "    result[k] = 1\n",
    "for k in list2:\n",
    "    result[k] = 2\n",
    "\n",
    "result0 = [0] * len(predict1)\n",
    "\n",
    "for k in list0:\n",
    "    result0[k] = 0\n",
    "for k in list1:\n",
    "    result0[k] = 1\n",
    "for k in list2:\n",
    "    result0[k] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if the non-positive are all set to label 0 Accuracy：   100.0 %\n",
      "if the non-positive are all set to label 1/2 Accuracy：    82.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"if the non-positive are all set to label 0 Accuracy：{:8.6} %\".format((result0 == iris_y_test).mean() * 100))\n",
    "print(\"if the non-positive are all set to label 1/2 Accuracy：{:8.6} %\".format((result == iris_y_test).mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVR(One vs Rest)\n",
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_y_train_0_1 = list(iris_y_train)\n",
    "iris_y_train_1_2 = list(iris_y_train)\n",
    "iris_y_train_0_2 = list(iris_y_train)\n",
    "\n",
    "iris_x_train_0_1 = list(iris_x_train) \n",
    "iris_x_train_1_2 = list(iris_x_train)\n",
    "iris_x_train_0_2 = list(iris_x_train)\n",
    "\n",
    "ylist0 = []\n",
    "ylist1 = []\n",
    "ylist2 = []\n",
    "\n",
    "for i in range(len(iris_y_train)):\n",
    "    if iris_y_train[i] == 2:\n",
    "        ylist2.append(i)\n",
    "        \n",
    "    if iris_y_train[i] == 0:\n",
    "        ylist0.append(i)\n",
    "        \n",
    "    if iris_y_train[i] == 1:\n",
    "        ylist1.append(i)\n",
    "\n",
    "\n",
    "ylist0.reverse()\n",
    "ylist1.reverse()\n",
    "ylist2.reverse()\n",
    "\n",
    "\n",
    "for k in ylist2:\n",
    "    del iris_y_train_0_1[k]\n",
    "    del iris_x_train_0_1[k]\n",
    "\n",
    "for k in ylist0:\n",
    "    del iris_y_train_1_2[k]\n",
    "    del iris_x_train_1_2[k]\n",
    "    \n",
    "for k in ylist1:\n",
    "    del iris_y_train_0_2[k]\n",
    "    del iris_x_train_0_2[k]\n",
    "\n",
    "# 1 is positive and 0 is negative \n",
    "iris_x_train_0_1 = np.array(iris_x_train_0_1)\n",
    "iris_y_train_0_1 = np.array(iris_y_train_0_1)\n",
    "iris_y_train_0_1 = np.where(iris_y_train_0_1 == 0, -1, 1).astype(float)\n",
    "\n",
    "# 2 is positive and 1 is negative \n",
    "iris_x_train_1_2 = np.array(iris_x_train_1_2)\n",
    "iris_y_train_1_2 = np.array(iris_y_train_1_2)\n",
    "iris_y_train_1_2 = np.where(iris_y_train_1_2 == 1, -1, 1).astype(float)\n",
    "\n",
    "# 2 is positive and 0 is negative \n",
    "iris_x_train_0_2 = np.array(iris_x_train_0_2)\n",
    "iris_y_train_0_2 = np.array(iris_y_train_0_2)\n",
    "iris_y_train_0_2 = np.where(iris_y_train_0_2 == 0, -1, 1).astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.5715e+01  1.2526e+02  6e+02  4e+00  1e+01\n",
      " 1:  5.9157e+01 -1.7550e+01  1e+02  4e-01  1e+00\n",
      " 2:  1.7584e+01  8.3929e+00  1e+01  2e-02  7e-02\n",
      " 3:  1.4898e+01  1.0949e+01  4e+00  9e-03  3e-02\n",
      " 4:  1.3801e+01  1.2175e+01  2e+00  3e-03  9e-03\n",
      " 5:  1.3207e+01  1.2830e+01  4e-01  5e-04  1e-03\n",
      " 6:  1.3078e+01  1.2943e+01  1e-01  1e-04  4e-04\n",
      " 7:  1.3017e+01  1.2992e+01  3e-02  1e-15  2e-12\n",
      " 8:  1.3005e+01  1.3004e+01  6e-04  1e-15  5e-12\n",
      " 9:  1.3005e+01  1.3005e+01  6e-06  1e-15  2e-11\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.2694e+01  8.5896e+01  4e+02  3e+00  3e+01\n",
      " 1:  2.1707e+01 -1.7735e+01  6e+01  3e-01  2e+00\n",
      " 2:  2.5018e+00 -9.8669e-01  4e+00  1e-02  1e-01\n",
      " 3:  3.7026e-01  7.9160e-02  3e-01  1e-04  1e-03\n",
      " 4:  2.1866e-01  1.5251e-01  7e-02  3e-05  2e-04\n",
      " 5:  2.2145e-01  1.8613e-01  4e-02  7e-06  6e-05\n",
      " 6:  2.0596e-01  2.0098e-01  5e-03  8e-07  7e-06\n",
      " 7:  2.0377e-01  2.0359e-01  2e-04  2e-08  1e-07\n",
      " 8:  2.0368e-01  2.0368e-01  2e-06  2e-10  2e-09\n",
      " 9:  2.0368e-01  2.0368e-01  2e-08  2e-12  2e-11\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.1342e+01  1.0030e+02  5e+02  4e+00  2e+01\n",
      " 1:  3.1633e+01 -2.1615e+01  7e+01  3e-01  2e+00\n",
      " 2:  5.2390e+00 -1.7462e+00  8e+00  3e-02  2e-01\n",
      " 3:  1.0683e+00  3.4623e-01  8e-01  1e-03  8e-03\n",
      " 4:  8.4301e-01  5.3755e-01  3e-01  5e-04  3e-03\n",
      " 5:  8.4603e-01  6.8330e-01  2e-01  4e-05  2e-04\n",
      " 6:  7.5308e-01  7.4467e-01  8e-03  1e-06  9e-06\n",
      " 7:  7.4813e-01  7.4799e-01  1e-04  2e-08  1e-07\n",
      " 8:  7.4806e-01  7.4806e-01  2e-06  2e-10  1e-09\n",
      " 9:  7.4806e-01  7.4806e-01  2e-08  2e-12  1e-11\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.04603488,  0.52172272, -1.00316443, -0.46418011]),\n",
       " 1.4505624971977702)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_soft_0_1 = SVM_soft()\n",
    "svm_soft_1_2 = SVM_soft()\n",
    "svm_soft_0_2 = SVM_soft()\n",
    "\n",
    "\n",
    "svm_soft_0_1.fit(iris_x_train_0_1, iris_y_train_0_1, 1)\n",
    "svm_soft_1_2.fit(iris_x_train_1_2, iris_y_train_1_2, 1)\n",
    "svm_soft_0_2.fit(iris_x_train_0_2, iris_y_train_0_2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict0_1 = svm_soft_0.predict(iris_x_test).astype(int)\n",
    "predict1_2 = svm_soft_1.predict(iris_x_test).astype(int)\n",
    "predict0_2 = svm_soft_2.predict(iris_x_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [-1] *  len(predict0_1)\n",
    "for i in range(len(final)):\n",
    "    if predict0_1[i] == -1 and predict0_2[i] == -1:\n",
    "        final[i] = 0\n",
    "        continue\n",
    "    if predict0_1[i] == 1 and predict1_2[i] == -1:\n",
    "        final[i] = 1\n",
    "        continue\n",
    "    if predict1_2[i] == 1 and predict1_2[i] == 1:\n",
    "        final[i] = 2\n",
    "        continue\n",
    "    final[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Accuracy：    56.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing set Accuracy：{:8.6} %\".format((final == iris_y_test).mean() * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. OVR \n",
    "    * Advantage:\n",
    "       For problems with large number of labels, it requires to train less SVM. It is also relatively easier to implement in the preprocessing period. For small size problem(like this 3 label), it has a good performance\n",
    "    * Disadvantage:\n",
    "        Each SVM are treated equally while they may have different credibility. For problems with large number of labels, it may fail to give a satisfying result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. OVO \n",
    "    * Advantage: For problems with large number of labels, it may give a satisfying result as the voting strategy will be very useful in large scale.\n",
    "    * Disadvantage: For problems with small number of labels, it may fail to give a satisfying result as the voting strategy will still cause a lot of uncertainty. For problems with large number of labels, it requires to train more SVMs and it is more computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
